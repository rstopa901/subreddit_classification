{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3df6aeae-a73a-48e2-92f0-eaed3a98cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import math\n",
    "import spacy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, \n",
    "                                             TfidfVectorizer)\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import (cross_val_score, GridSearchCV, \n",
    "                                     train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8c0ea82a-28e4-4e3f-bac4-a237f6a1b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "ow_cod_df = pd.read_csv('data/ow_cod_df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6c91b43b-9ade-4b84-852b-ea2528bf0250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50491"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ow_cod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "721364a9-c96e-4454-8ca2-78771bc46463",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6076e73-2b0f-4ee9-8a7f-ef2948fba111",
   "metadata": {},
   "outputs": [],
   "source": [
    "ow_cod_df.loc[:, 'spacy_lemmatized'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41e82402-143e-48b4-8b11-54813f66b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column, spacy_lemmatized, which is lemmatized reviews\n",
    "# leaving out aux, punct, and pron since we want to keep these original values\n",
    "for i in ow_cod_df.index:\n",
    "    doc = nlp(ow_cod_df['title_selftext'].loc[i])\n",
    "    lemmatized = ' '.join([token.lemma_ for token in doc if token.pos_ not in ['AUX', 'PUNCT', 'PRON']])\n",
    "    ow_cod_df['spacy_lemmatized'].loc[i] = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3fe7f-166d-45a2-b349-ac9356d73c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save spacy lemmatized to csv\n",
    "ow_cod_df.to_csv('data/ow_cod_df_clean_lemmatized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a9d832-7e8a-4e72-b382-8f9b92ecf5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ow_cod_df = pd.read_csv('data/ow_cod_df_clean_lemmatized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652bca72-c1f9-4978-b6d6-81fadb83e93e",
   "metadata": {},
   "source": [
    "I will test both logistic regression models and random forest for classification as they are both widely used for their performance and are industry standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882da57a-829a-4c1d-8cc0-06b99ea65bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50460"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for spacy lemmatization, drop nulls\n",
    "ow_cod_df.dropna(subset='spacy_lemmatized', inplace=True)\n",
    "len(ow_cod_df) # 50460, dropped 31 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85377dc2-54e0-4edb-b5c2-c6814110a0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = ow_cod_df['spacy_lemmatized']\n",
    "y = ow_cod_df['subreddit_ow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a581608-aa63-4da0-9c3e-7ba29f6a95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=901, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77810571-8b80-4938-9916-fd6251684624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37845,), (12615,), (37845,), (12615,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e08d96-b65c-4c4e-a810-08296b88cfc0",
   "metadata": {},
   "source": [
    "#### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e0bee4-adbb-4d37-afbd-8278599e6cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for storing results\n",
    "results_df = pd.DataFrame(columns=['model', 'params', 'train_score', 'test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cead9ea-c5cf-4a04-a170-b9f8eda00979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for logistic regression using TFIDF\n",
    "# using saga solver to accomodate l2, and no penalty options (after several iterations l2 was clearly preferred over l1 for all logistic regression\n",
    "# so we only consider l2)\n",
    "logreg_pipe = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter=10_000, random_state=901))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a5e1c69-d082-40f9-9dfe-d7fcb7f8f383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf_vect', TfidfVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(max_iter=10000,\n",
       "                                                           random_state=901))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lr__C': [2.5, 2.0, 1.5],\n",
       "                         'lr__penalty': ['l2', 'none'],\n",
       "                         'tfidf_vect__stop_words': [None, 'english']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing with english stopwords and no stop words\n",
    "# testing out l2, and no penalty (after several runs l2 was preferred over l1 for all logreg models)\n",
    "# ideal C was above 1.0 so testing several values\n",
    "params = {\n",
    "    'tfidf_vect__stop_words': [None, 'english'],\n",
    "    'lr__penalty': ['l2', 'none'],\n",
    "    'lr__C': [2.5, 2.0, 1.5]   \n",
    "}\n",
    "# using gridsearch to look at all possibilities\n",
    "gs_logreg_tfidf = GridSearchCV(logreg_pipe, param_grid=params, n_jobs=-1)\n",
    "# fit to training data\n",
    "gs_logreg_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "318d1a57-0cda-4673-a692-56fb7fdf4bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 2.5, 'lr__penalty': 'l2', 'tfidf_vect__stop_words': 'english'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_tfidf.best_params_\n",
    "# {'lr__C': 2.5, 'lr__penalty': 'l2', 'tfidf_vect__stop_words': 'english'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9da89835-2173-4fec-800c-ac8a2efda86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9078874355925486, 0.8580261593341261)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_tfidf.best_estimator_.score(X_train, y_train), gs_logreg_tfidf.best_estimator_.score(X_test, y_test)\n",
    "# (0.9078874355925486, 0.8580261593341261)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cc97bea-a39a-44b6-81c6-81e378bd7528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rstop\\AppData\\Local\\Temp\\ipykernel_11292\\2731731862.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(gs_logreg_tfidf_dict, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# save results to dataframe\n",
    "# 'model', 'params', 'train_score', 'test_score'])\n",
    "gs_logreg_tfidf_dict = {'model': gs_logreg_tfidf, \n",
    "                      'params': gs_logreg_tfidf.best_params_, \n",
    "                      'train_score': gs_logreg_tfidf.best_estimator_.score(X_train, y_train), \n",
    "                      'test_score': gs_logreg_tfidf.best_estimator_.score(X_test, y_test)}\n",
    "results_df = results_df.append(gs_logreg_tfidf_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e131b63-76b6-4d5b-b132-1877bf053a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying lemmatized, countvectorizer, logreg with same params as before\n",
    "logreg_pipe_cv = Pipeline([\n",
    "    ('cvx', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter=10_000, random_state=901))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1526ff6-9a1a-449b-aa30-0d32e3f15ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvx', CountVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(max_iter=10000,\n",
       "                                                           random_state=901))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvx__stop_words': [None, 'english'],\n",
       "                         'lr__C': [2.5, 2.0, 1.5],\n",
       "                         'lr__penalty': ['l2', 'none']})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing with english stopwords and no stop words\n",
    "# testing out l2, and no penalty\n",
    "# ideal C was above 1.0 so testing several values\n",
    "params = {\n",
    "    'cvx__stop_words': [None, 'english'],\n",
    "    'lr__penalty': ['l2', 'none'],\n",
    "    'lr__C': [2.5, 2.0, 1.5]\n",
    "    \n",
    "}\n",
    "# using gridsearch to look at all possibilities\n",
    "gs_logreg_cv = GridSearchCV(logreg_pipe_cv, param_grid=params, n_jobs=-1)\n",
    "# fit to training data\n",
    "gs_logreg_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d37643d-c007-4b05-885a-f598513a3d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvx__stop_words': None, 'lr__C': 1.5, 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_cv.best_params_\n",
    "# {'cvx__stop_words': None, 'lr__C': 1.5, 'lr__penalty': 'l2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0189776-69c6-406a-ae3b-98f4077b7c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9212577619236358, 0.8608799048751486)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_cv.best_estimator_.score(X_train, y_train), gs_logreg_cv.best_estimator_.score(X_test, y_test)\n",
    "# (0.9212577619236358, 0.8608799048751486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0fb9814-3e3f-4f25-be00-31005834c5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rstop\\AppData\\Local\\Temp\\ipykernel_11292\\1869905441.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(gs_logreg_cv_dict, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# save results to dataframe\n",
    "# 'model', 'params', 'train_score', 'test_score'])\n",
    "gs_logreg_cv_dict = {'model': gs_logreg_cv, \n",
    "                      'params': gs_logreg_cv.best_params_, \n",
    "                      'train_score': gs_logreg_cv.best_estimator_.score(X_train, y_train), \n",
    "                      'test_score': gs_logreg_cv.best_estimator_.score(X_test, y_test)}\n",
    "results_df = results_df.append(gs_logreg_cv_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0810e40-3420-4f28-8be1-09e9154039f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('tfidf...</td>\n",
       "      <td>{'lr__C': 2.5, 'lr__penalty': 'l2', 'tfidf_vec...</td>\n",
       "      <td>0.907887</td>\n",
       "      <td>0.858026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('cvx',...</td>\n",
       "      <td>{'cvx__stop_words': None, 'lr__C': 1.5, 'lr__p...</td>\n",
       "      <td>0.921258</td>\n",
       "      <td>0.860880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  \\\n",
       "0  GridSearchCV(estimator=Pipeline(steps=[('tfidf...   \n",
       "1  GridSearchCV(estimator=Pipeline(steps=[('cvx',...   \n",
       "\n",
       "                                              params  train_score  test_score  \n",
       "0  {'lr__C': 2.5, 'lr__penalty': 'l2', 'tfidf_vec...     0.907887    0.858026  \n",
       "1  {'cvx__stop_words': None, 'lr__C': 1.5, 'lr__p...     0.921258    0.860880  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c2dcf-3d1e-45b4-9154-ecb17d5c2052",
   "metadata": {},
   "source": [
    "We take a look at the best model from above but on non-lemmatized X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bf9b482-e78b-4099-96a8-d13484f7b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = ow_cod_df['title_selftext']\n",
    "y = ow_cod_df['subreddit_ow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28962e79-0aaa-483b-acc0-83d305d06c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=901, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4978d9a-f896-46b2-8266-ff0b41a19a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37845,), (12615,), (37845,), (12615,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e762074-bb6b-48eb-b064-d824f6d9d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe_cv_nonlemmatized = Pipeline([\n",
    "    ('cvx', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter=10_000, random_state=901, C=1.5, penalty='l2'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9969d11e-18e3-4024-bd4c-54e20e65570c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvx', CountVectorizer()),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1.5, max_iter=10000, random_state=901))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit best model (logreg, cv) without lemmatization\n",
    "logreg_pipe_cv_nonlemmatized.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd4d79fa-66f6-4565-a9d5-ba1eb9e76bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9336239926014005, 0.8608799048751486)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pipe_cv_nonlemmatized.score(X_train, y_train), logreg_pipe_cv_nonlemmatized.score(X_test, y_test)\n",
    "# (0.9336239926014005, 0.8608799048751486)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcab628b-766c-4656-b0e4-4266ba5834b0",
   "metadata": {},
   "source": [
    "Since the non-lemmatized version scored slightly worse on logistic regression for the testing set and it is similar anyway, we will use lemmatization for the remainder of the modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445417d-ae31-4baa-ba98-e35ef86e6e56",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cc061b3-1357-4407-86be-cd18777200fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = ow_cod_df['spacy_lemmatized']\n",
    "y = ow_cod_df['subreddit_ow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c83df960-d76e-4143-b63e-d5c0202707f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=901, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a162317e-e877-40a9-b198-70544db08a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37845,), (12615,), (37845,), (12615,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d4f263c-b629-4a8f-a5d4-f14abf807df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit random forest with tfidf using grid search\n",
    "rf_tfidf_pipe = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f32503b5-37a8-4902-aae1-a933eabcb55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf_vect', TfidfVectorizer()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tfidf_vect__stop_words': [None, 'english']})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# several options of max_depth and other parameters were explored for the rf but the default performed the best\n",
    "params = {\n",
    "    'tfidf_vect__stop_words': [None, 'english']}\n",
    "gs_rf_tfidf = GridSearchCV(rf_tfidf_pipe, param_grid=params, n_jobs=-1)\n",
    "gs_rf_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "371e3e70-152e-4b9d-8993-f13a609abc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf_vect__stop_words': 'english'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_tfidf.best_params_\n",
    "# {'tfidf_vect__stop_words': 'english'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e0bae9e-a3cb-4d0c-ad4b-867b06d42bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9891399128022196, 0.8462148236226714)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_tfidf.best_estimator_.score(X_train, y_train), gs_rf_tfidf.best_estimator_.score(X_test, y_test)\n",
    "# (0.9891399128022196, 0.8462148236226714)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ac28b8d-25be-4286-978e-fd1f7831ed46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rstop\\AppData\\Local\\Temp\\ipykernel_11292\\1250717841.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(gs_rf_tfidf_dict, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# save results to dataframe\n",
    "# 'model', 'params', 'train_score', 'test_score'\n",
    "gs_rf_tfidf_dict = {'model': gs_rf_tfidf, \n",
    "                      'params': gs_rf_tfidf.best_params_, \n",
    "                      'train_score': gs_rf_tfidf.best_estimator_.score(X_train, y_train), \n",
    "                      'test_score': gs_rf_tfidf.best_estimator_.score(X_test, y_test)}\n",
    "results_df = results_df.append(gs_rf_tfidf_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec3b841e-9691-4d5a-8a48-dc81bb92eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit random forest with cv using grid search\n",
    "rf_tfidf_pipe = Pipeline([\n",
    "    ('cvx', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e09c38d3-a82d-4d4a-864b-9c2c2559c491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvx', CountVectorizer()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1, param_grid={'cvx__stop_words': [None, 'english']})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# several options of max_depth and other parameters were explored for the rf but the default performed the best (on the test set)\n",
    "params = {\n",
    "    'cvx__stop_words': [None, 'english']\n",
    "}\n",
    "gs_rf_cv = GridSearchCV(rf_tfidf_pipe, param_grid=params, n_jobs=-1)\n",
    "gs_rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecd17716-57c3-441e-b3da-48b833639286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvx__stop_words': 'english'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_cv.best_params_\n",
    "# {'cvx__stop_words': 'english'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1feef87-ec09-4f6a-b286-5bb6c0198c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.989272030651341, 0.8390804597701149)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_cv.best_estimator_.score(X_train, y_train), gs_rf_cv.best_estimator_.score(X_test, y_test)\n",
    "# (0.989272030651341, 0.8390804597701149)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "583e7805-736a-49ca-a49e-b1340a9b60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rstop\\AppData\\Local\\Temp\\ipykernel_11292\\517635097.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(gs_rf_cv_dict, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# save results to dataframe\n",
    "# 'model', 'params', 'train_score', 'test_score'\n",
    "gs_rf_cv_dict = {'model': gs_rf_cv, \n",
    "                      'params': gs_rf_cv.best_params_, \n",
    "                      'train_score': gs_rf_cv.best_estimator_.score(X_train, y_train), \n",
    "                      'test_score': gs_rf_cv.best_estimator_.score(X_test, y_test)}\n",
    "results_df = results_df.append(gs_rf_cv_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91cb8515-e175-4340-93ce-7be3cf4b6556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('tfidf...</td>\n",
       "      <td>{'lr__C': 2.5, 'lr__penalty': 'l2', 'tfidf_vec...</td>\n",
       "      <td>0.907887</td>\n",
       "      <td>0.858026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('cvx',...</td>\n",
       "      <td>{'cvx__stop_words': None, 'lr__C': 1.5, 'lr__p...</td>\n",
       "      <td>0.921258</td>\n",
       "      <td>0.860880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('tfidf...</td>\n",
       "      <td>{'rf__max_depth': 25, 'tfidf_vect__stop_words'...</td>\n",
       "      <td>0.729581</td>\n",
       "      <td>0.721681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('cvx',...</td>\n",
       "      <td>{'cvx__stop_words': 'english', 'rf__max_depth'...</td>\n",
       "      <td>0.732091</td>\n",
       "      <td>0.725961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('tfidf...</td>\n",
       "      <td>{'tfidf_vect__stop_words': 'english'}</td>\n",
       "      <td>0.989140</td>\n",
       "      <td>0.846215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('cvx',...</td>\n",
       "      <td>{'cvx__stop_words': 'english'}</td>\n",
       "      <td>0.989272</td>\n",
       "      <td>0.839080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  \\\n",
       "0  GridSearchCV(estimator=Pipeline(steps=[('tfidf...   \n",
       "1  GridSearchCV(estimator=Pipeline(steps=[('cvx',...   \n",
       "2  GridSearchCV(estimator=Pipeline(steps=[('tfidf...   \n",
       "3  GridSearchCV(estimator=Pipeline(steps=[('cvx',...   \n",
       "4  GridSearchCV(estimator=Pipeline(steps=[('tfidf...   \n",
       "5  GridSearchCV(estimator=Pipeline(steps=[('cvx',...   \n",
       "\n",
       "                                              params  train_score  test_score  \n",
       "0  {'lr__C': 2.5, 'lr__penalty': 'l2', 'tfidf_vec...     0.907887    0.858026  \n",
       "1  {'cvx__stop_words': None, 'lr__C': 1.5, 'lr__p...     0.921258    0.860880  \n",
       "2  {'rf__max_depth': 25, 'tfidf_vect__stop_words'...     0.729581    0.721681  \n",
       "3  {'cvx__stop_words': 'english', 'rf__max_depth'...     0.732091    0.725961  \n",
       "4              {'tfidf_vect__stop_words': 'english'}     0.989140    0.846215  \n",
       "5                     {'cvx__stop_words': 'english'}     0.989272    0.839080  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9b2a65-1e48-411c-9606-aabad93b1ffa",
   "metadata": {},
   "source": [
    "After looking at results, we see that the logisic regression with CountVectorizer performed the best. We continue to tune this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42ad482f-0054-4379-bbcc-b1e6914be88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying lemmatized, countvectorizer, logreg with same params as before\n",
    "logreg_pipe_cv = Pipeline([\n",
    "    ('cvx', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter=10_000, random_state=901))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4db2c034-f5a7-45ab-91d6-e3ec2edae617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvx', CountVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(max_iter=10000,\n",
       "                                                           random_state=901))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvx__stop_words': [None],\n",
       "                         'lr__C': [1.2, 1.3, 1.4, 1.5, 1.6, 1.7],\n",
       "                         'lr__penalty': ['l2']})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing with english stopwords and no stop words\n",
    "# testing out l2, and no penalty\n",
    "# ideal C was above 1.0 so testing several values\n",
    "params = {\n",
    "    'cvx__stop_words': [None],\n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__C': [1.2, 1.3, 1.4, 1.5, 1.6, 1.7]\n",
    "    \n",
    "}\n",
    "# using gridsearch to look at all possibilities\n",
    "gs_logreg_cv = GridSearchCV(logreg_pipe_cv, param_grid=params, n_jobs=-1)\n",
    "# fit to training data\n",
    "gs_logreg_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bdfa15b2-537c-4e45-8920-ef74aa428825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvx__stop_words': None, 'lr__C': 1.3, 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_cv.best_params_\n",
    "# {'cvx__stop_words': None, 'lr__C': 1.3, 'lr__penalty': 'l2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4123d14-387e-4c12-91f5-80daca02ae3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9177170035671819, 0.8613555291319858)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_cv.best_estimator_.score(X_train, y_train), gs_logreg_cv.best_estimator_.score(X_test, y_test)\n",
    "# (0.9177170035671819, 0.8613555291319858)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "43891e36-5a4c-42e1-99e8-6d0bda0db099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rstop\\AppData\\Local\\Temp\\ipykernel_11292\\1814882970.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(gs_logreg_cv_dict_2, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# save results to dataframe\n",
    "# 'model', 'params', 'train_score', 'test_score'\n",
    "gs_logreg_cv_dict_2 = {'model': gs_logreg_cv, \n",
    "                      'params': gs_logreg_cv.best_params_, \n",
    "                      'train_score': gs_logreg_cv.best_estimator_.score(X_train, y_train), \n",
    "                      'test_score': gs_logreg_cv.best_estimator_.score(X_test, y_test)}\n",
    "results_df = results_df.append(gs_logreg_cv_dict_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b57c76e2-bb24-4299-a2b8-4090a304d904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('tfidf...</td>\n",
       "      <td>{'lr__C': 2.5, 'lr__penalty': 'l2', 'tfidf_vec...</td>\n",
       "      <td>0.907887</td>\n",
       "      <td>0.858026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('cvx',...</td>\n",
       "      <td>{'cvx__stop_words': None, 'lr__C': 1.5, 'lr__p...</td>\n",
       "      <td>0.921258</td>\n",
       "      <td>0.860880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('tfidf...</td>\n",
       "      <td>{'rf__max_depth': 25, 'tfidf_vect__stop_words'...</td>\n",
       "      <td>0.729581</td>\n",
       "      <td>0.721681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('cvx',...</td>\n",
       "      <td>{'cvx__stop_words': 'english', 'rf__max_depth'...</td>\n",
       "      <td>0.732091</td>\n",
       "      <td>0.725961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('tfidf...</td>\n",
       "      <td>{'tfidf_vect__stop_words': 'english'}</td>\n",
       "      <td>0.989140</td>\n",
       "      <td>0.846215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('cvx',...</td>\n",
       "      <td>{'cvx__stop_words': 'english'}</td>\n",
       "      <td>0.989272</td>\n",
       "      <td>0.839080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('cvx',...</td>\n",
       "      <td>{'cvx__stop_words': None, 'lr__C': 1.3, 'lr__p...</td>\n",
       "      <td>0.917717</td>\n",
       "      <td>0.861356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  \\\n",
       "0  GridSearchCV(estimator=Pipeline(steps=[('tfidf...   \n",
       "1  GridSearchCV(estimator=Pipeline(steps=[('cvx',...   \n",
       "2  GridSearchCV(estimator=Pipeline(steps=[('tfidf...   \n",
       "3  GridSearchCV(estimator=Pipeline(steps=[('cvx',...   \n",
       "4  GridSearchCV(estimator=Pipeline(steps=[('tfidf...   \n",
       "5  GridSearchCV(estimator=Pipeline(steps=[('cvx',...   \n",
       "6  GridSearchCV(estimator=Pipeline(steps=[('cvx',...   \n",
       "\n",
       "                                              params  train_score  test_score  \n",
       "0  {'lr__C': 2.5, 'lr__penalty': 'l2', 'tfidf_vec...     0.907887    0.858026  \n",
       "1  {'cvx__stop_words': None, 'lr__C': 1.5, 'lr__p...     0.921258    0.860880  \n",
       "2  {'rf__max_depth': 25, 'tfidf_vect__stop_words'...     0.729581    0.721681  \n",
       "3  {'cvx__stop_words': 'english', 'rf__max_depth'...     0.732091    0.725961  \n",
       "4              {'tfidf_vect__stop_words': 'english'}     0.989140    0.846215  \n",
       "5                     {'cvx__stop_words': 'english'}     0.989272    0.839080  \n",
       "6  {'cvx__stop_words': None, 'lr__C': 1.3, 'lr__p...     0.917717    0.861356  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f239b-d316-4cfc-86bb-bce0eb39084e",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055da372-9400-42a1-83d8-5fb93fae52e7",
   "metadata": {},
   "source": [
    "Our final model is a logistic regression with:\n",
    "* no stop words\n",
    "* penalty l2 (ridge)\n",
    "* C = 1.3\n",
    "\n",
    "The model performance was:\n",
    "* training: ~ 0.918\n",
    "* test: ~ 0.861"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67b82f-9f0f-40a8-92b1-d140ded1b253",
   "metadata": {},
   "source": [
    "The baseline for our model is the most frequent occurence which is ~0.66, so our model performs better than the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "29e86d74-11f9-442b-aa62-0d9fd8aecdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_ow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.65979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.34021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit_ow\n",
       "0       0.65979\n",
       "1       0.34021"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ow_cod_df['subreddit_ow'].value_counts(normalize=True).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd6ba90-17db-4eb4-a8fc-a67a535647ff",
   "metadata": {},
   "source": [
    "#### Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6983f1cc-cbe9-4e91-ae1f-bf183792a7cc",
   "metadata": {},
   "source": [
    "First, we know that based on how the trianing score was much higher than our test score, the model we have is overfitted. However, a test score ofd 0.861 is good so we still keep this as our best model.\n",
    "Next, we look at coefficients in our model for interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5e87a518-b7db-4668-a87e-5db9429bad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining just one case of model\n",
    "logreg_pipe_cv = Pipeline([\n",
    "    ('cvx', CountVectorizer(stop_words=None)),\n",
    "    ('lr', LogisticRegression(max_iter=10_000, random_state=901, C=1.3, penalty='l2'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43648673-35a1-46ec-9206-b50a4fab2de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvx', CountVectorizer()),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1.3, max_iter=10000, random_state=901))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pipe_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c14fbd67-b343-4e7b-b84f-5037d74e21e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9177170035671819, 0.8613555291319858)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_cv.score(X_train, y_train), gs_logreg_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a17f3dab-87ae-428e-88f0-a2dc6659ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_coefs = pd.DataFrame(zip(gs_logreg_cv.best_estimator_.named_steps['cvx'].get_feature_names_out(), np.transpose(gs_logreg_cv.best_estimator_.named_steps['lr'].coef_[0])), columns=['features', 'coef']) \n",
    "\n",
    "# source: https://stackoverflow.com/questions/57924484/finding-coefficients-for-logistic-regression-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c1b38729-f807-4f48-9821-cece85e0b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_coefs['abs_coef'] = abs(logreg_coefs['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ef347569-008f-4b34-8a7f-2573ab6382f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of most common words\n",
    "cv_unigrams = CountVectorizer(max_features=10000, stop_words='english')\n",
    "unigrams = cv_unigrams.fit_transform(ow_cod_df['spacy_lemmatized'])\n",
    "unigrams = pd.DataFrame(unigrams.todense(), columns=cv_unigrams.get_feature_names_out())\n",
    "\n",
    "unigrams = unigrams.sum().sort_values(ascending = False).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c67cea1a-b506-49d5-bf9d-49a532c58edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = unigrams.join(logreg_coefs.set_index('features')).rename(columns={0: 'frequency'}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d815881a-3a67-4d24-a603-204e334af635",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams['importance'] = unigrams['frequency'] * unigrams['abs_coef']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "35be1fa5-2381-4514-964e-b74262320ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weapon</th>\n",
       "      <td>4198</td>\n",
       "      <td>-1.737435</td>\n",
       "      <td>1.737435</td>\n",
       "      <td>7293.750456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gun</th>\n",
       "      <td>3922</td>\n",
       "      <td>-1.758101</td>\n",
       "      <td>1.758101</td>\n",
       "      <td>6895.271494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tank</th>\n",
       "      <td>2404</td>\n",
       "      <td>2.570142</td>\n",
       "      <td>2.570142</td>\n",
       "      <td>6178.621558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>17381</td>\n",
       "      <td>0.322415</td>\n",
       "      <td>0.322415</td>\n",
       "      <td>5603.887647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>3165</td>\n",
       "      <td>1.681789</td>\n",
       "      <td>1.681789</td>\n",
       "      <td>5322.861228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>2827</td>\n",
       "      <td>1.800907</td>\n",
       "      <td>1.800907</td>\n",
       "      <td>5091.163829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skin</th>\n",
       "      <td>4416</td>\n",
       "      <td>1.071068</td>\n",
       "      <td>1.071068</td>\n",
       "      <td>4729.837153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp</th>\n",
       "      <td>1315</td>\n",
       "      <td>3.584932</td>\n",
       "      <td>3.584932</td>\n",
       "      <td>4714.185602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miplayer</th>\n",
       "      <td>1625</td>\n",
       "      <td>-2.669387</td>\n",
       "      <td>2.669387</td>\n",
       "      <td>4337.753111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game</th>\n",
       "      <td>27527</td>\n",
       "      <td>-0.147480</td>\n",
       "      <td>0.147480</td>\n",
       "      <td>4059.692512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character</th>\n",
       "      <td>1761</td>\n",
       "      <td>1.847426</td>\n",
       "      <td>1.847426</td>\n",
       "      <td>3253.317820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>competitive</th>\n",
       "      <td>1150</td>\n",
       "      <td>2.691966</td>\n",
       "      <td>2.691966</td>\n",
       "      <td>3095.761053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>3350</td>\n",
       "      <td>0.909965</td>\n",
       "      <td>0.909965</td>\n",
       "      <td>3048.383873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>role</th>\n",
       "      <td>1051</td>\n",
       "      <td>2.847017</td>\n",
       "      <td>2.847017</td>\n",
       "      <td>2992.215352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loadout</th>\n",
       "      <td>917</td>\n",
       "      <td>-3.187378</td>\n",
       "      <td>3.187378</td>\n",
       "      <td>2922.825720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activision</th>\n",
       "      <td>883</td>\n",
       "      <td>-3.199707</td>\n",
       "      <td>3.199707</td>\n",
       "      <td>2825.341483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heal</th>\n",
       "      <td>1137</td>\n",
       "      <td>2.476042</td>\n",
       "      <td>2.476042</td>\n",
       "      <td>2815.260061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kill</th>\n",
       "      <td>6045</td>\n",
       "      <td>-0.455092</td>\n",
       "      <td>0.455092</td>\n",
       "      <td>2751.030621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mission</th>\n",
       "      <td>1146</td>\n",
       "      <td>-2.345115</td>\n",
       "      <td>2.345115</td>\n",
       "      <td>2687.501472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steam</th>\n",
       "      <td>1063</td>\n",
       "      <td>-2.438952</td>\n",
       "      <td>2.438952</td>\n",
       "      <td>2592.606248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>5226</td>\n",
       "      <td>0.484370</td>\n",
       "      <td>0.484370</td>\n",
       "      <td>2531.315947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main</th>\n",
       "      <td>1350</td>\n",
       "      <td>1.863486</td>\n",
       "      <td>1.863486</td>\n",
       "      <td>2515.706217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unlock</th>\n",
       "      <td>3414</td>\n",
       "      <td>-0.720671</td>\n",
       "      <td>0.720671</td>\n",
       "      <td>2460.369929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spawn</th>\n",
       "      <td>1652</td>\n",
       "      <td>-1.424187</td>\n",
       "      <td>1.424187</td>\n",
       "      <td>2352.756119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>damage</th>\n",
       "      <td>2448</td>\n",
       "      <td>0.950321</td>\n",
       "      <td>0.950321</td>\n",
       "      <td>2326.385649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>4828</td>\n",
       "      <td>0.467970</td>\n",
       "      <td>0.467970</td>\n",
       "      <td>2259.361173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbmm</th>\n",
       "      <td>672</td>\n",
       "      <td>-3.309616</td>\n",
       "      <td>3.309616</td>\n",
       "      <td>2224.061719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>1130</td>\n",
       "      <td>1.850023</td>\n",
       "      <td>1.850023</td>\n",
       "      <td>2090.525930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rifle</th>\n",
       "      <td>1024</td>\n",
       "      <td>-2.001723</td>\n",
       "      <td>2.001723</td>\n",
       "      <td>2049.764040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iw</th>\n",
       "      <td>600</td>\n",
       "      <td>-3.329563</td>\n",
       "      <td>3.329563</td>\n",
       "      <td>1997.737667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             frequency      coef  abs_coef   importance\n",
       "weapon            4198 -1.737435  1.737435  7293.750456\n",
       "gun               3922 -1.758101  1.758101  6895.271494\n",
       "tank              2404  2.570142  2.570142  6178.621558\n",
       "play             17381  0.322415  0.322415  5603.887647\n",
       "support           3165  1.681789  1.681789  5322.861228\n",
       "rank              2827  1.800907  1.800907  5091.163829\n",
       "skin              4416  1.071068  1.071068  4729.837153\n",
       "comp              1315  3.584932  3.584932  4714.185602\n",
       "miplayer          1625 -2.669387  2.669387  4337.753111\n",
       "game             27527 -0.147480  0.147480  4059.692512\n",
       "character         1761  1.847426  1.847426  3253.317820\n",
       "competitive       1150  2.691966  2.691966  3095.761053\n",
       "season            3350  0.909965  0.909965  3048.383873\n",
       "role              1051  2.847017  2.847017  2992.215352\n",
       "loadout            917 -3.187378  3.187378  2922.825720\n",
       "activision         883 -3.199707  3.199707  2825.341483\n",
       "heal              1137  2.476042  2.476042  2815.260061\n",
       "kill              6045 -0.455092  0.455092  2751.030621\n",
       "mission           1146 -2.345115  2.345115  2687.501472\n",
       "steam             1063 -2.438952  2.438952  2592.606248\n",
       "new               5226  0.484370  0.484370  2531.315947\n",
       "main              1350  1.863486  1.863486  2515.706217\n",
       "unlock            3414 -0.720671  0.720671  2460.369929\n",
       "spawn             1652 -1.424187  1.424187  2352.756119\n",
       "damage            2448  0.950321  0.950321  2326.385649\n",
       "team              4828  0.467970  0.467970  2259.361173\n",
       "sbmm               672 -3.309616  3.309616  2224.061719\n",
       "ability           1130  1.850023  1.850023  2090.525930\n",
       "rifle             1024 -2.001723  2.001723  2049.764040\n",
       "iw                 600 -3.329563  3.329563  1997.737667"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams.sort_values(by='importance', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fbd5c3-86ba-45fe-aa96-f97a6ac9df58",
   "metadata": {},
   "source": [
    "The table above gives the coefficient weighted by the frequency of a word as a heuristic for word importance in classification. Words with negative coefficients are words used to classify COD MW2 posts and positive ones for Overwatch 2.\n",
    "\n",
    "As examples for interpretation:\n",
    "* A one-word increase in occurance of \"weapon\" in a post means that the post being for Overwatch 2 subreddit is is ~0.18 times as likely\n",
    "* A one-word increase in occurance of \"tank\" in a post means that the post being for Overwatch 2 subreddit is is 13 times as likely\n",
    "\n",
    "(note: since we removed the occurence of \"ult\", the word \"multiplayer\" turned into \"miplayer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82ed32-2f47-490b-9237-65883af6901e",
   "metadata": {},
   "source": [
    "From the table, we can see that:\n",
    "\n",
    "1. The following words are more commonly associated with Overwatch 2 subreddit posts:\n",
    "* tank\n",
    "* support\n",
    "* rank\n",
    "* comp/ competative\n",
    "* role\n",
    "* heal\n",
    "\n",
    "\n",
    "2. The following words are more commonly associated with COD MW2 subreddit posts:\n",
    "* multiplayer\n",
    "* loadout\n",
    "* activision\n",
    "* gun\n",
    "* weapon\n",
    "\n",
    "For conclusions/remarks, please see readme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
